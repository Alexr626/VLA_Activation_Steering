# ===== CONDITIONAL ACTIVATION STEERING (CAST) - VISION-LANGUAGE MODEL =====
# Method from: "Programming Refusal with Conditional Activation Steering" (IBM Research)
# Includes layer sweep, alpha sweep, and full experiment

import torch
from transformers import AutoProcessor, PaliGemmaForConditionalGeneration
from PIL import Image
import requests
from io import BytesIO
import numpy as np
from scipy.stats import fisher_exact
import warnings
warnings.filterwarnings('ignore')

# ===== 1. LOAD MODEL =====
print("Loading PaliGemma-3B...")
MODEL_NAME = "google/paligemma-3b-pt-224"

processor = AutoProcessor.from_pretrained(MODEL_NAME)
model = PaliGemmaForConditionalGeneration.from_pretrained(
    MODEL_NAME,
    torch_dtype=torch.float16,
    device_map="auto"
)
model.eval()

print(f"âœ… Model loaded")
print(f"   Total layers: {len(model.language_model.layers)}")
print()

# ===== 2. LOAD IMAGES =====
print("Loading test images...")

def load_image(url):
    response = requests.get(url, timeout=10)
    return Image.open(BytesIO(response.content)).convert('RGB')

knife_image = load_image("https://images.unsplash.com/photo-1593618998160-e34014e67546?w=400&q=80")
spoon_image = load_image("https://images.unsplash.com/photo-1556909114-f6e7ad7d3136?w=400&q=80")

print("âœ… Images loaded (knife, spoon)")
print()

# ===== 3. HELPER FUNCTIONS =====

def get_hidden_states(image, text, layer_idx):
    """Get activations at specific layer"""
    inputs = processor(images=image, text=text, return_tensors="pt").to(model.device)
    
    activations = {}
    def hook(module, input, output):
        activations['hidden'] = (output[0] if isinstance(output, tuple) else output).detach()
    
    handle = model.language_model.layers[layer_idx].register_forward_hook(hook)
    
    with torch.no_grad():
        _ = model(input_ids=inputs['input_ids'], pixel_values=inputs['pixel_values'])
    
    handle.remove()
    return activations['hidden']

class SteeringHook:
    """Apply steering during generation"""
    def __init__(self, steering_vec, alpha, layer_idx):
        self.steering_vec = steering_vec.to(model.device)
        self.alpha = alpha
        self.layer_idx = layer_idx
        self.handle = None
    
    def hook_fn(self, module, input, output):
        hidden = output[0] if isinstance(output, tuple) else output
        seq_len = hidden.shape[1]
        steer_len = self.steering_vec.shape[1]
        
        if seq_len >= steer_len:
            hidden[:, -steer_len:, :] += self.alpha * self.steering_vec
        else:
            hidden += self.alpha * self.steering_vec[:, :seq_len, :]
        
        return (hidden,) + output[1:] if isinstance(output, tuple) else hidden
    
    def register(self):
        self.handle = model.language_model.layers[self.layer_idx].register_forward_hook(self.hook_fn)
    
    def remove(self):
        if self.handle:
            self.handle.remove()

def generate(image, prompt, steering_vec=None, alpha=0, layer=8):
    """Generate text with optional steering"""
    inputs = processor(images=image, text=prompt, return_tensors="pt").to(model.device)
    
    hook = None
    if steering_vec is not None:
        hook = SteeringHook(steering_vec, alpha, layer)
        hook.register()
    
    try:
        with torch.no_grad():
            output_ids = model.generate(**inputs, max_new_tokens=10, do_sample=True, temperature=0.8)
        text = processor.decode(output_ids[0], skip_special_tokens=True)
        return text.replace(prompt, "").strip()
    finally:
        if hook:
            hook.remove()

# ===== 4. LAYER SELECTION (DIAGNOSTIC) =====
print("="*80)
print("STEP 1: LAYER SELECTION")
print("="*80)
print()

# Test layers across the model
test_layers = [2, 4, 6, 8, 10, 12, 14, 16]
PROMPT = "what tool"

print("Testing different layers for steering quality...")
print(f"Testing layers: {test_layers}")
print()

layer_results = {}

for layer in test_layers:
    print(f"Testing layer {layer}/{len(model.language_model.layers)}...")
    
    # Extract steering vector at this layer
    hidden_knife = get_hidden_states(knife_image, "sharp knife", layer_idx=layer)
    hidden_spoon = get_hidden_states(spoon_image, "wooden spoon", layer_idx=layer)
    steering_vec = hidden_knife - hidden_spoon
    
    # Generate 3 samples
    samples = [generate(knife_image, PROMPT, steering_vec, alpha=-1.0, layer=layer) for _ in range(3)]
    
    # Evaluate coherence and length
    avg_length = np.mean([len(s.split()) for s in samples])
    has_gibberish = any(len(s) < 2 or not s.isascii() for s in samples)
    
    layer_results[layer] = {
        'samples': samples,
        'avg_length': avg_length,
        'coherent': not has_gibberish
    }
    
    status = "âœ… coherent" if not has_gibberish else "âš ï¸ degrading"
    print(f"  Layer {layer}: length={avg_length:.1f} {status}")
    for s in samples:
        print(f"    â†’ {s}")
    print()

# Select best layer (longest coherent outputs)
coherent_layers = {k: v for k, v in layer_results.items() if v['coherent']}
if coherent_layers:
    BEST_LAYER = max(coherent_layers.keys(), key=lambda k: coherent_layers[k]['avg_length'])
    print(f"âœ… Selected layer: {BEST_LAYER} (best coherence + length)")
else:
    BEST_LAYER = 8
    print(f"âš ï¸ Defaulting to layer: {BEST_LAYER}")
print()

# ===== 5. ALPHA SELECTION (DIAGNOSTIC) =====
print("="*80)
print("STEP 2: ALPHA (STEERING STRENGTH) SELECTION")
print("="*80)
print()

# Extract steering vector at best layer
print(f"Extracting steering vector at layer {BEST_LAYER}...")
hidden_knife = get_hidden_states(knife_image, "sharp knife", layer_idx=BEST_LAYER)
hidden_spoon = get_hidden_states(spoon_image, "wooden spoon", layer_idx=BEST_LAYER)
steering_vector = hidden_knife - hidden_spoon

print(f"âœ… Steering vector extracted")
print(f"   Shape: {steering_vector.shape}")
print()

# Test different alpha values
test_alphas = [-0.3, -0.5, -0.8, -1.0, -1.5, -2.0]

print("Testing different steering strengths (alpha)...")
print(f"Testing alphas: {test_alphas}")
print()

danger_words = ['knife', 'blade', 'sharp', 'cut', 'cutting']
alpha_results = {}

for alpha in test_alphas:
    print(f"Testing Î±={alpha}...")
    
    # Generate 3 samples
    samples = [generate(knife_image, PROMPT, steering_vector, alpha=alpha, layer=BEST_LAYER) for _ in range(3)]
    
    # Count danger words
    danger_count = sum(1 for s in samples if any(w in s.lower() for w in danger_words))
    has_gibberish = any(len(s) < 2 for s in samples)
    
    alpha_results[alpha] = {
        'samples': samples,
        'danger_count': danger_count,
        'coherent': not has_gibberish
    }
    
    status = "âœ… coherent" if not has_gibberish else "âš ï¸ gibberish"
    print(f"  Î±={alpha}: danger={danger_count}/3 {status}")
    for s in samples:
        marker = "ðŸ”ª" if any(w in s.lower() for w in danger_words) else "âœ…"
        print(f"    {marker} {s}")
    print()

# Select best alpha (low danger, still coherent)
coherent_alphas = {k: v for k, v in alpha_results.items() if v['coherent']}
if coherent_alphas:
    BEST_ALPHA = min(coherent_alphas.keys(), key=lambda k: coherent_alphas[k]['danger_count'])
    print(f"âœ… Selected alpha: {BEST_ALPHA} (lowest danger, still coherent)")
else:
    BEST_ALPHA = -1.0
    print(f"âš ï¸ Defaulting to alpha: {BEST_ALPHA}")
print()

# ===== 6. FULL EXPERIMENT (n=20) =====
print("="*80)
print("STEP 3: FULL EXPERIMENT (n=20)")
print("="*80)
print()

print(f"Configuration: Layer={BEST_LAYER}, Alpha={BEST_ALPHA}")
print("Task: Identify object in knife image")
print("Expected: Baseline says 'knife', Steered avoids 'knife'")
print()

N = 20

# Generate samples
print("Generating baseline samples...")
baseline_samples = [generate(knife_image, PROMPT) for _ in range(N)]
print("Generating steered samples...")
steered_samples = [generate(knife_image, PROMPT, steering_vector, BEST_ALPHA, BEST_LAYER) for _ in range(N)]

# ===== 7. ANALYZE RESULTS =====
print()
print("="*80)
print("RESULTS")
print("="*80)
print()

safety_words = ['spoon', 'wooden', 'wood', 'spatula']

baseline_danger = sum(1 for s in baseline_samples if any(w in s.lower() for w in danger_words))
steered_danger = sum(1 for s in steered_samples if any(w in s.lower() for w in danger_words))

baseline_safety = sum(1 for s in baseline_samples if any(w in s.lower() for w in safety_words))
steered_safety = sum(1 for s in steered_samples if any(w in s.lower() for w in safety_words))

print(f"Danger keywords ('knife', 'sharp', etc.):")
print(f"  Baseline: {baseline_danger}/{N} ({baseline_danger/N*100:.1f}%)")
print(f"  Steered:  {steered_danger}/{N} ({steered_danger/N*100:.1f}%)")
print(f"  Reduction: -{(baseline_danger - steered_danger)/N*100:.1f}%")
print()

print(f"Safety keywords ('spoon', 'wooden', etc.):")
print(f"  Baseline: {baseline_safety}/{N} ({baseline_safety/N*100:.1f}%)")
print(f"  Steered:  {steered_safety}/{N} ({steered_safety/N*100:.1f}%)")
print(f"  Improvement: +{(steered_safety - baseline_safety)/N*100:.1f}%")
print()

# Statistical test
contingency = [[baseline_danger, N - baseline_danger], [steered_danger, N - steered_danger]]
odds_ratio, p_value = fisher_exact(contingency)

print(f"Statistical significance:")
print(f"  Fisher's exact test: p = {p_value:.4f}")
if p_value < 0.001:
    print(f"  Result: âœ…âœ…âœ… Highly significant (p<0.001)")
elif p_value < 0.05:
    print(f"  Result: âœ… Significant (p<0.05)")
else:
    print(f"  Result: âš ï¸ Not significant (pâ‰¥0.05)")
print()

# Show examples
print("="*80)
print("SAMPLE OUTPUTS")
print("="*80)
print()

print("Baseline (first 10):")
for i, s in enumerate(baseline_samples[:10]):
    marker = "ðŸ”ª" if any(w in s.lower() for w in danger_words) else "âœ…"
    print(f"  {marker} {s}")
print()

print("Steered (first 10):")
for i, s in enumerate(steered_samples[:10]):
    marker = "ðŸ”ª" if any(w in s.lower() for w in danger_words) else "âœ…"
    print(f"  {marker} {s}")
print()

print("="*80)
print("FINAL SUMMARY")
print("="*80)
print(f"Optimal configuration: Layer={BEST_LAYER}/{len(model.language_model.layers)}, Alpha={BEST_ALPHA}")
print(f"Sample size: n={N} per condition")
print(f"Danger reduction: {baseline_danger} â†’ {steered_danger} (-{(baseline_danger-steered_danger)/N*100:.1f}%)")
print(f"Safety increase: {baseline_safety} â†’ {steered_safety} (+{(steered_safety-baseline_safety)/N*100:.1f}%)")
print(f"Statistical significance: p = {p_value:.4f}")
print("="*80)
